WARNING: Logging before InitGoogleLogging() is written to STDERR
W0321 15:14:16.386389 15283 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0321 15:14:16.386440 15283 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0321 15:14:16.386445 15283 _caffe.cpp:125] Net('./model/VGG_FACE_deploy.prototxt', 1, weights='./model/VGG_FACE.caffemodel')
I0321 15:14:16.387668 15283 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./model/VGG_FACE_deploy.prototxt
I0321 15:14:16.387753 15283 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0321 15:14:16.387786 15283 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./model/VGG_FACE_deploy.prototxt
I0321 15:14:16.387812 15283 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0321 15:14:16.387819 15283 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0321 15:14:16.387981 15283 net.cpp:58] Initializing net from parameters: 
name: "VGG_FACE_16_layers"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 2622
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0321 15:14:16.388097 15283 layer_factory.hpp:77] Creating layer input
I0321 15:14:16.388118 15283 net.cpp:100] Creating Layer input
I0321 15:14:16.388125 15283 net.cpp:408] input -> data
I0321 15:14:16.398109 15283 net.cpp:150] Setting up input
I0321 15:14:16.398150 15283 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0321 15:14:16.398155 15283 net.cpp:165] Memory required for data: 602112
I0321 15:14:16.398161 15283 layer_factory.hpp:77] Creating layer conv1_1
I0321 15:14:16.398180 15283 net.cpp:100] Creating Layer conv1_1
I0321 15:14:16.398185 15283 net.cpp:434] conv1_1 <- data
I0321 15:14:16.398205 15283 net.cpp:408] conv1_1 -> conv1_1
I0321 15:14:16.541198 15283 net.cpp:150] Setting up conv1_1
I0321 15:14:16.541240 15283 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0321 15:14:16.541246 15283 net.cpp:165] Memory required for data: 13447168
I0321 15:14:16.541260 15283 layer_factory.hpp:77] Creating layer relu1_1
I0321 15:14:16.541272 15283 net.cpp:100] Creating Layer relu1_1
I0321 15:14:16.541278 15283 net.cpp:434] relu1_1 <- conv1_1
I0321 15:14:16.541296 15283 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0321 15:14:16.541438 15283 net.cpp:150] Setting up relu1_1
I0321 15:14:16.541448 15283 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0321 15:14:16.541452 15283 net.cpp:165] Memory required for data: 26292224
I0321 15:14:16.541457 15283 layer_factory.hpp:77] Creating layer conv1_2
I0321 15:14:16.541467 15283 net.cpp:100] Creating Layer conv1_2
I0321 15:14:16.541487 15283 net.cpp:434] conv1_2 <- conv1_1
I0321 15:14:16.541496 15283 net.cpp:408] conv1_2 -> conv1_2
I0321 15:14:16.542218 15283 net.cpp:150] Setting up conv1_2
I0321 15:14:16.542230 15283 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0321 15:14:16.542235 15283 net.cpp:165] Memory required for data: 39137280
I0321 15:14:16.542245 15283 layer_factory.hpp:77] Creating layer relu1_2
I0321 15:14:16.542254 15283 net.cpp:100] Creating Layer relu1_2
I0321 15:14:16.542259 15283 net.cpp:434] relu1_2 <- conv1_2
I0321 15:14:16.542280 15283 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0321 15:14:16.542424 15283 net.cpp:150] Setting up relu1_2
I0321 15:14:16.542438 15283 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0321 15:14:16.542443 15283 net.cpp:165] Memory required for data: 51982336
I0321 15:14:16.542448 15283 layer_factory.hpp:77] Creating layer pool1
I0321 15:14:16.542471 15283 net.cpp:100] Creating Layer pool1
I0321 15:14:16.542476 15283 net.cpp:434] pool1 <- conv1_2
I0321 15:14:16.542484 15283 net.cpp:408] pool1 -> pool1
I0321 15:14:16.542522 15283 net.cpp:150] Setting up pool1
I0321 15:14:16.542531 15283 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0321 15:14:16.542536 15283 net.cpp:165] Memory required for data: 55193600
I0321 15:14:16.542541 15283 layer_factory.hpp:77] Creating layer conv2_1
I0321 15:14:16.542549 15283 net.cpp:100] Creating Layer conv2_1
I0321 15:14:16.542556 15283 net.cpp:434] conv2_1 <- pool1
I0321 15:14:16.542562 15283 net.cpp:408] conv2_1 -> conv2_1
I0321 15:14:16.544595 15283 net.cpp:150] Setting up conv2_1
I0321 15:14:16.544612 15283 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0321 15:14:16.544618 15283 net.cpp:165] Memory required for data: 61616128
I0321 15:14:16.544630 15283 layer_factory.hpp:77] Creating layer relu2_1
I0321 15:14:16.544637 15283 net.cpp:100] Creating Layer relu2_1
I0321 15:14:16.544643 15283 net.cpp:434] relu2_1 <- conv2_1
I0321 15:14:16.544651 15283 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0321 15:14:16.545061 15283 net.cpp:150] Setting up relu2_1
I0321 15:14:16.545073 15283 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0321 15:14:16.545078 15283 net.cpp:165] Memory required for data: 68038656
I0321 15:14:16.545083 15283 layer_factory.hpp:77] Creating layer conv2_2
I0321 15:14:16.545096 15283 net.cpp:100] Creating Layer conv2_2
I0321 15:14:16.545102 15283 net.cpp:434] conv2_2 <- conv2_1
I0321 15:14:16.545110 15283 net.cpp:408] conv2_2 -> conv2_2
I0321 15:14:16.546273 15283 net.cpp:150] Setting up conv2_2
I0321 15:14:16.546285 15283 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0321 15:14:16.546290 15283 net.cpp:165] Memory required for data: 74461184
I0321 15:14:16.546299 15283 layer_factory.hpp:77] Creating layer relu2_2
I0321 15:14:16.546308 15283 net.cpp:100] Creating Layer relu2_2
I0321 15:14:16.546313 15283 net.cpp:434] relu2_2 <- conv2_2
I0321 15:14:16.546334 15283 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0321 15:14:16.546456 15283 net.cpp:150] Setting up relu2_2
I0321 15:14:16.546465 15283 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0321 15:14:16.546470 15283 net.cpp:165] Memory required for data: 80883712
I0321 15:14:16.546475 15283 layer_factory.hpp:77] Creating layer pool2
I0321 15:14:16.546483 15283 net.cpp:100] Creating Layer pool2
I0321 15:14:16.546489 15283 net.cpp:434] pool2 <- conv2_2
I0321 15:14:16.546509 15283 net.cpp:408] pool2 -> pool2
I0321 15:14:16.546546 15283 net.cpp:150] Setting up pool2
I0321 15:14:16.546566 15283 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0321 15:14:16.546586 15283 net.cpp:165] Memory required for data: 82489344
I0321 15:14:16.546591 15283 layer_factory.hpp:77] Creating layer conv3_1
I0321 15:14:16.546598 15283 net.cpp:100] Creating Layer conv3_1
I0321 15:14:16.546604 15283 net.cpp:434] conv3_1 <- pool2
I0321 15:14:16.546612 15283 net.cpp:408] conv3_1 -> conv3_1
I0321 15:14:16.547787 15283 net.cpp:150] Setting up conv3_1
I0321 15:14:16.547801 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.547806 15283 net.cpp:165] Memory required for data: 85700608
I0321 15:14:16.547817 15283 layer_factory.hpp:77] Creating layer relu3_1
I0321 15:14:16.547826 15283 net.cpp:100] Creating Layer relu3_1
I0321 15:14:16.547832 15283 net.cpp:434] relu3_1 <- conv3_1
I0321 15:14:16.547837 15283 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0321 15:14:16.547961 15283 net.cpp:150] Setting up relu3_1
I0321 15:14:16.547971 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.547976 15283 net.cpp:165] Memory required for data: 88911872
I0321 15:14:16.547981 15283 layer_factory.hpp:77] Creating layer conv3_2
I0321 15:14:16.547988 15283 net.cpp:100] Creating Layer conv3_2
I0321 15:14:16.548007 15283 net.cpp:434] conv3_2 <- conv3_1
I0321 15:14:16.548020 15283 net.cpp:408] conv3_2 -> conv3_2
I0321 15:14:16.549770 15283 net.cpp:150] Setting up conv3_2
I0321 15:14:16.549783 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.549789 15283 net.cpp:165] Memory required for data: 92123136
I0321 15:14:16.549810 15283 layer_factory.hpp:77] Creating layer relu3_2
I0321 15:14:16.549818 15283 net.cpp:100] Creating Layer relu3_2
I0321 15:14:16.549823 15283 net.cpp:434] relu3_2 <- conv3_2
I0321 15:14:16.549844 15283 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0321 15:14:16.549994 15283 net.cpp:150] Setting up relu3_2
I0321 15:14:16.550004 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.550009 15283 net.cpp:165] Memory required for data: 95334400
I0321 15:14:16.550014 15283 layer_factory.hpp:77] Creating layer conv3_3
I0321 15:14:16.550022 15283 net.cpp:100] Creating Layer conv3_3
I0321 15:14:16.550029 15283 net.cpp:434] conv3_3 <- conv3_2
I0321 15:14:16.550050 15283 net.cpp:408] conv3_3 -> conv3_3
I0321 15:14:16.551815 15283 net.cpp:150] Setting up conv3_3
I0321 15:14:16.551836 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.551841 15283 net.cpp:165] Memory required for data: 98545664
I0321 15:14:16.551849 15283 layer_factory.hpp:77] Creating layer relu3_3
I0321 15:14:16.551861 15283 net.cpp:100] Creating Layer relu3_3
I0321 15:14:16.551867 15283 net.cpp:434] relu3_3 <- conv3_3
I0321 15:14:16.551873 15283 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0321 15:14:16.551990 15283 net.cpp:150] Setting up relu3_3
I0321 15:14:16.551998 15283 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0321 15:14:16.552003 15283 net.cpp:165] Memory required for data: 101756928
I0321 15:14:16.552008 15283 layer_factory.hpp:77] Creating layer pool3
I0321 15:14:16.552016 15283 net.cpp:100] Creating Layer pool3
I0321 15:14:16.552022 15283 net.cpp:434] pool3 <- conv3_3
I0321 15:14:16.552029 15283 net.cpp:408] pool3 -> pool3
I0321 15:14:16.552067 15283 net.cpp:150] Setting up pool3
I0321 15:14:16.552075 15283 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0321 15:14:16.552080 15283 net.cpp:165] Memory required for data: 102559744
I0321 15:14:16.552085 15283 layer_factory.hpp:77] Creating layer conv4_1
I0321 15:14:16.552094 15283 net.cpp:100] Creating Layer conv4_1
I0321 15:14:16.552100 15283 net.cpp:434] conv4_1 <- pool3
I0321 15:14:16.552108 15283 net.cpp:408] conv4_1 -> conv4_1
I0321 15:14:16.555102 15283 net.cpp:150] Setting up conv4_1
I0321 15:14:16.555126 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.555131 15283 net.cpp:165] Memory required for data: 104165376
I0321 15:14:16.555141 15283 layer_factory.hpp:77] Creating layer relu4_1
I0321 15:14:16.555150 15283 net.cpp:100] Creating Layer relu4_1
I0321 15:14:16.555156 15283 net.cpp:434] relu4_1 <- conv4_1
I0321 15:14:16.555162 15283 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0321 15:14:16.555291 15283 net.cpp:150] Setting up relu4_1
I0321 15:14:16.555301 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.555306 15283 net.cpp:165] Memory required for data: 105771008
I0321 15:14:16.555312 15283 layer_factory.hpp:77] Creating layer conv4_2
I0321 15:14:16.555321 15283 net.cpp:100] Creating Layer conv4_2
I0321 15:14:16.555327 15283 net.cpp:434] conv4_2 <- conv4_1
I0321 15:14:16.555335 15283 net.cpp:408] conv4_2 -> conv4_2
I0321 15:14:16.559432 15283 net.cpp:150] Setting up conv4_2
I0321 15:14:16.559463 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.559468 15283 net.cpp:165] Memory required for data: 107376640
I0321 15:14:16.559484 15283 layer_factory.hpp:77] Creating layer relu4_2
I0321 15:14:16.559494 15283 net.cpp:100] Creating Layer relu4_2
I0321 15:14:16.559512 15283 net.cpp:434] relu4_2 <- conv4_2
I0321 15:14:16.559518 15283 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0321 15:14:16.559921 15283 net.cpp:150] Setting up relu4_2
I0321 15:14:16.559932 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.559937 15283 net.cpp:165] Memory required for data: 108982272
I0321 15:14:16.559942 15283 layer_factory.hpp:77] Creating layer conv4_3
I0321 15:14:16.559958 15283 net.cpp:100] Creating Layer conv4_3
I0321 15:14:16.559979 15283 net.cpp:434] conv4_3 <- conv4_2
I0321 15:14:16.559988 15283 net.cpp:408] conv4_3 -> conv4_3
I0321 15:14:16.563942 15283 net.cpp:150] Setting up conv4_3
I0321 15:14:16.563972 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.563977 15283 net.cpp:165] Memory required for data: 110587904
I0321 15:14:16.563987 15283 layer_factory.hpp:77] Creating layer relu4_3
I0321 15:14:16.563998 15283 net.cpp:100] Creating Layer relu4_3
I0321 15:14:16.564004 15283 net.cpp:434] relu4_3 <- conv4_3
I0321 15:14:16.564012 15283 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0321 15:14:16.564124 15283 net.cpp:150] Setting up relu4_3
I0321 15:14:16.564134 15283 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0321 15:14:16.564139 15283 net.cpp:165] Memory required for data: 112193536
I0321 15:14:16.564144 15283 layer_factory.hpp:77] Creating layer pool4
I0321 15:14:16.564153 15283 net.cpp:100] Creating Layer pool4
I0321 15:14:16.564158 15283 net.cpp:434] pool4 <- conv4_3
I0321 15:14:16.564165 15283 net.cpp:408] pool4 -> pool4
I0321 15:14:16.564203 15283 net.cpp:150] Setting up pool4
I0321 15:14:16.564211 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.564216 15283 net.cpp:165] Memory required for data: 112594944
I0321 15:14:16.564221 15283 layer_factory.hpp:77] Creating layer conv5_1
I0321 15:14:16.564231 15283 net.cpp:100] Creating Layer conv5_1
I0321 15:14:16.564237 15283 net.cpp:434] conv5_1 <- pool4
I0321 15:14:16.564244 15283 net.cpp:408] conv5_1 -> conv5_1
I0321 15:14:16.568437 15283 net.cpp:150] Setting up conv5_1
I0321 15:14:16.568467 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.568472 15283 net.cpp:165] Memory required for data: 112996352
I0321 15:14:16.568482 15283 layer_factory.hpp:77] Creating layer relu5_1
I0321 15:14:16.568493 15283 net.cpp:100] Creating Layer relu5_1
I0321 15:14:16.568500 15283 net.cpp:434] relu5_1 <- conv5_1
I0321 15:14:16.568506 15283 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0321 15:14:16.568629 15283 net.cpp:150] Setting up relu5_1
I0321 15:14:16.568639 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.568645 15283 net.cpp:165] Memory required for data: 113397760
I0321 15:14:16.568650 15283 layer_factory.hpp:77] Creating layer conv5_2
I0321 15:14:16.568660 15283 net.cpp:100] Creating Layer conv5_2
I0321 15:14:16.568666 15283 net.cpp:434] conv5_2 <- conv5_1
I0321 15:14:16.568673 15283 net.cpp:408] conv5_2 -> conv5_2
I0321 15:14:16.572435 15283 net.cpp:150] Setting up conv5_2
I0321 15:14:16.572463 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.572468 15283 net.cpp:165] Memory required for data: 113799168
I0321 15:14:16.572477 15283 layer_factory.hpp:77] Creating layer relu5_2
I0321 15:14:16.572487 15283 net.cpp:100] Creating Layer relu5_2
I0321 15:14:16.572494 15283 net.cpp:434] relu5_2 <- conv5_2
I0321 15:14:16.572499 15283 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0321 15:14:16.572618 15283 net.cpp:150] Setting up relu5_2
I0321 15:14:16.572628 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.572633 15283 net.cpp:165] Memory required for data: 114200576
I0321 15:14:16.572638 15283 layer_factory.hpp:77] Creating layer conv5_3
I0321 15:14:16.572649 15283 net.cpp:100] Creating Layer conv5_3
I0321 15:14:16.572654 15283 net.cpp:434] conv5_3 <- conv5_2
I0321 15:14:16.572661 15283 net.cpp:408] conv5_3 -> conv5_3
I0321 15:14:16.576375 15283 net.cpp:150] Setting up conv5_3
I0321 15:14:16.576405 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.576411 15283 net.cpp:165] Memory required for data: 114601984
I0321 15:14:16.576421 15283 layer_factory.hpp:77] Creating layer relu5_3
I0321 15:14:16.576431 15283 net.cpp:100] Creating Layer relu5_3
I0321 15:14:16.576436 15283 net.cpp:434] relu5_3 <- conv5_3
I0321 15:14:16.576443 15283 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0321 15:14:16.576562 15283 net.cpp:150] Setting up relu5_3
I0321 15:14:16.576571 15283 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0321 15:14:16.576582 15283 net.cpp:165] Memory required for data: 115003392
I0321 15:14:16.576588 15283 layer_factory.hpp:77] Creating layer pool5
I0321 15:14:16.576597 15283 net.cpp:100] Creating Layer pool5
I0321 15:14:16.576603 15283 net.cpp:434] pool5 <- conv5_3
I0321 15:14:16.576611 15283 net.cpp:408] pool5 -> pool5
I0321 15:14:16.576653 15283 net.cpp:150] Setting up pool5
I0321 15:14:16.576661 15283 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0321 15:14:16.576666 15283 net.cpp:165] Memory required for data: 115103744
I0321 15:14:16.576671 15283 layer_factory.hpp:77] Creating layer fc6
I0321 15:14:16.576683 15283 net.cpp:100] Creating Layer fc6
I0321 15:14:16.576689 15283 net.cpp:434] fc6 <- pool5
I0321 15:14:16.576695 15283 net.cpp:408] fc6 -> fc6
I0321 15:14:16.705274 15283 net.cpp:150] Setting up fc6
I0321 15:14:16.705308 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.705314 15283 net.cpp:165] Memory required for data: 115120128
I0321 15:14:16.705325 15283 layer_factory.hpp:77] Creating layer relu6
I0321 15:14:16.705335 15283 net.cpp:100] Creating Layer relu6
I0321 15:14:16.705343 15283 net.cpp:434] relu6 <- fc6
I0321 15:14:16.705348 15283 net.cpp:395] relu6 -> fc6 (in-place)
I0321 15:14:16.705909 15283 net.cpp:150] Setting up relu6
I0321 15:14:16.705921 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.705926 15283 net.cpp:165] Memory required for data: 115136512
I0321 15:14:16.705932 15283 layer_factory.hpp:77] Creating layer drop6
I0321 15:14:16.705943 15283 net.cpp:100] Creating Layer drop6
I0321 15:14:16.705950 15283 net.cpp:434] drop6 <- fc6
I0321 15:14:16.705957 15283 net.cpp:395] drop6 -> fc6 (in-place)
I0321 15:14:16.705987 15283 net.cpp:150] Setting up drop6
I0321 15:14:16.705996 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.706001 15283 net.cpp:165] Memory required for data: 115152896
I0321 15:14:16.706007 15283 layer_factory.hpp:77] Creating layer fc7
I0321 15:14:16.706015 15283 net.cpp:100] Creating Layer fc7
I0321 15:14:16.706022 15283 net.cpp:434] fc7 <- fc6
I0321 15:14:16.706027 15283 net.cpp:408] fc7 -> fc7
I0321 15:14:16.727243 15283 net.cpp:150] Setting up fc7
I0321 15:14:16.727291 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.727296 15283 net.cpp:165] Memory required for data: 115169280
I0321 15:14:16.727309 15283 layer_factory.hpp:77] Creating layer relu7
I0321 15:14:16.727324 15283 net.cpp:100] Creating Layer relu7
I0321 15:14:16.727329 15283 net.cpp:434] relu7 <- fc7
I0321 15:14:16.727336 15283 net.cpp:395] relu7 -> fc7 (in-place)
I0321 15:14:16.727541 15283 net.cpp:150] Setting up relu7
I0321 15:14:16.727552 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.727557 15283 net.cpp:165] Memory required for data: 115185664
I0321 15:14:16.727562 15283 layer_factory.hpp:77] Creating layer drop7
I0321 15:14:16.727571 15283 net.cpp:100] Creating Layer drop7
I0321 15:14:16.727576 15283 net.cpp:434] drop7 <- fc7
I0321 15:14:16.727583 15283 net.cpp:395] drop7 -> fc7 (in-place)
I0321 15:14:16.727610 15283 net.cpp:150] Setting up drop7
I0321 15:14:16.727618 15283 net.cpp:157] Top shape: 1 4096 (4096)
I0321 15:14:16.727624 15283 net.cpp:165] Memory required for data: 115202048
I0321 15:14:16.727629 15283 layer_factory.hpp:77] Creating layer fc8
I0321 15:14:16.727638 15283 net.cpp:100] Creating Layer fc8
I0321 15:14:16.727643 15283 net.cpp:434] fc8 <- fc7
I0321 15:14:16.727650 15283 net.cpp:408] fc8 -> fc8
I0321 15:14:16.740624 15283 net.cpp:150] Setting up fc8
I0321 15:14:16.740656 15283 net.cpp:157] Top shape: 1 2622 (2622)
I0321 15:14:16.740674 15283 net.cpp:165] Memory required for data: 115212536
I0321 15:14:16.740698 15283 layer_factory.hpp:77] Creating layer prob
I0321 15:14:16.740708 15283 net.cpp:100] Creating Layer prob
I0321 15:14:16.740715 15283 net.cpp:434] prob <- fc8
I0321 15:14:16.740721 15283 net.cpp:408] prob -> prob
I0321 15:14:16.740945 15283 net.cpp:150] Setting up prob
I0321 15:14:16.740954 15283 net.cpp:157] Top shape: 1 2622 (2622)
I0321 15:14:16.740959 15283 net.cpp:165] Memory required for data: 115223024
I0321 15:14:16.740965 15283 net.cpp:228] prob does not need backward computation.
I0321 15:14:16.740978 15283 net.cpp:228] fc8 does not need backward computation.
I0321 15:14:16.740983 15283 net.cpp:228] drop7 does not need backward computation.
I0321 15:14:16.740989 15283 net.cpp:228] relu7 does not need backward computation.
I0321 15:14:16.740994 15283 net.cpp:228] fc7 does not need backward computation.
I0321 15:14:16.740999 15283 net.cpp:228] drop6 does not need backward computation.
I0321 15:14:16.741003 15283 net.cpp:228] relu6 does not need backward computation.
I0321 15:14:16.741008 15283 net.cpp:228] fc6 does not need backward computation.
I0321 15:14:16.741014 15283 net.cpp:228] pool5 does not need backward computation.
I0321 15:14:16.741019 15283 net.cpp:228] relu5_3 does not need backward computation.
I0321 15:14:16.741024 15283 net.cpp:228] conv5_3 does not need backward computation.
I0321 15:14:16.741030 15283 net.cpp:228] relu5_2 does not need backward computation.
I0321 15:14:16.741035 15283 net.cpp:228] conv5_2 does not need backward computation.
I0321 15:14:16.741040 15283 net.cpp:228] relu5_1 does not need backward computation.
I0321 15:14:16.741045 15283 net.cpp:228] conv5_1 does not need backward computation.
I0321 15:14:16.741051 15283 net.cpp:228] pool4 does not need backward computation.
I0321 15:14:16.741056 15283 net.cpp:228] relu4_3 does not need backward computation.
I0321 15:14:16.741061 15283 net.cpp:228] conv4_3 does not need backward computation.
I0321 15:14:16.741066 15283 net.cpp:228] relu4_2 does not need backward computation.
I0321 15:14:16.741071 15283 net.cpp:228] conv4_2 does not need backward computation.
I0321 15:14:16.741077 15283 net.cpp:228] relu4_1 does not need backward computation.
I0321 15:14:16.741082 15283 net.cpp:228] conv4_1 does not need backward computation.
I0321 15:14:16.741088 15283 net.cpp:228] pool3 does not need backward computation.
I0321 15:14:16.741093 15283 net.cpp:228] relu3_3 does not need backward computation.
I0321 15:14:16.741098 15283 net.cpp:228] conv3_3 does not need backward computation.
I0321 15:14:16.741104 15283 net.cpp:228] relu3_2 does not need backward computation.
I0321 15:14:16.741108 15283 net.cpp:228] conv3_2 does not need backward computation.
I0321 15:14:16.741114 15283 net.cpp:228] relu3_1 does not need backward computation.
I0321 15:14:16.741119 15283 net.cpp:228] conv3_1 does not need backward computation.
I0321 15:14:16.741125 15283 net.cpp:228] pool2 does not need backward computation.
I0321 15:14:16.741130 15283 net.cpp:228] relu2_2 does not need backward computation.
I0321 15:14:16.741135 15283 net.cpp:228] conv2_2 does not need backward computation.
I0321 15:14:16.741142 15283 net.cpp:228] relu2_1 does not need backward computation.
I0321 15:14:16.741147 15283 net.cpp:228] conv2_1 does not need backward computation.
I0321 15:14:16.741152 15283 net.cpp:228] pool1 does not need backward computation.
I0321 15:14:16.741158 15283 net.cpp:228] relu1_2 does not need backward computation.
I0321 15:14:16.741163 15283 net.cpp:228] conv1_2 does not need backward computation.
I0321 15:14:16.741168 15283 net.cpp:228] relu1_1 does not need backward computation.
I0321 15:14:16.741173 15283 net.cpp:228] conv1_1 does not need backward computation.
I0321 15:14:16.741178 15283 net.cpp:228] input does not need backward computation.
I0321 15:14:16.741183 15283 net.cpp:270] This network produces output prob
I0321 15:14:16.741204 15283 net.cpp:283] Network initialization done.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 580013788
I0321 15:14:17.421195 15283 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./model/VGG_FACE.caffemodel
I0321 15:14:17.421221 15283 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0321 15:14:17.421226 15283 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
